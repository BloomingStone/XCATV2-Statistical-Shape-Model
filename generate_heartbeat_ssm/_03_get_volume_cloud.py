from pathlib import Path
import multiprocessing
from functools import partial
import os
import logging
from tqdm import tqdm
from typing import Annotated

import pyvista as pv
import nibabel as nib
import numpy as np
import typer

from . import project_root
from .entrypoint import app


logger = logging.getLogger(__name__)

def process_label_file(
    label_nii_path: Path, 
    vtk_dir: Path,
    max_point_num
):
    """处理单个label文件并保存VTK结果"""
    try:
        ssm_case_name = label_nii_path.parent.parent.name
        label_name = label_nii_path.stem.split(".")[0]
        vtk_file = vtk_dir / ssm_case_name / f"{label_name}.vtk"
        vtk_file.parent.mkdir(parents=True, exist_ok=True)
        
        label_nii = nib.load(str(label_nii_path))
        label_data = label_nii.get_fdata()
        label_ids = sorted(np.unique(label_data).astype(np.int8))[1:]
        volume_points_all = pv.PolyData()
        
        # TODO 使用volume时只是为了方便整体对齐，其实并不需要区分label
        for label_id in label_ids:
            assert label_id > 0
            points = np.argwhere(label_data == label_id)
            index = np.random.choice(points.shape[0], max_point_num, replace=False)
            points = points[index]
            volume_points = pv.PolyData(points.astype(np.float32))
            volume_points.point_data["label"] = np.ones(volume_points.n_points).astype(np.uint8) * label_id
            volume_points_all = volume_points_all.merge(volume_points)
        
        volume_points_all.save(str(vtk_file))
        return True
    except Exception as e:
        error_msg = f"Failed to process {label_nii_path}"
        logger.error(error_msg, exc_info=True)
        print(f"ERROR: {error_msg} - see processing_errors.log for details")
        return False

# TODO 当时使用surface进行配准会出问题，因此增加了生成volume cloud 并配准的步骤，但后续可能还需要进一步评估
@app.command()
def get_volume_cloud(
    ssm_nii_dir: Annotated[
        Path, typer.Argument(help="The directory containing the SSM NII files generated by generate_ssm_data.")
    ] = project_root / "data" / "output_ssm_nii",
    volume_vtk_dir: Annotated[
        Path, typer.Argument(help="The output directory to save the volume cloud VTK files.")
    ] = project_root / "data" / "output_ssm_vtk_volume",
    max_point_num: Annotated[
        int, typer.Option(help="The maximum number of points in the volume cloud.")
    ] = 1000,
    num_workers: Annotated[
        int, typer.Option(help="The number of multiprocessing to use. default is half of the number of CPU cores.")
    ] = max(os.cpu_count() // 2, 1)
):
    """
    Generate volume cloud of cavity from SSM NII files.[STEP 3]
    """
    assert ssm_nii_dir.is_dir(), f"{ssm_nii_dir} is not a directory"
    volume_vtk_dir.mkdir(parents=True, exist_ok=True)

    label_files = []
    for ssm_case in ssm_nii_dir.iterdir():
        if ssm_case.is_dir():
            label_dir = ssm_case / "label"
            label_files.extend(sorted(label_dir.glob("*.nii.gz")))
            
    with multiprocessing.Pool(processes=num_workers) as pool:
        worker_func = partial(
            process_label_file, 
            vtk_dir=volume_vtk_dir,
            max_point_num=max_point_num
        )
        
        with tqdm(total=len(label_files), desc="Processing files") as pbar:
            results = []
            for result in pool.imap_unordered(worker_func, label_files):
                results.append(result)
                pbar.update(1)

        success_count = sum(results)
        print(f"\nProcessing complete! Success: {success_count}/{len(label_files)}")


if __name__ == "__main__":
    typer.run(get_volume_cloud)